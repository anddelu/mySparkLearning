/**
  *要求示例为相同Key：[2015-07-01, 2015-08-06, 2015-09-10]的相邻时间之差的平均值，即 ((08-06 - 07-01) + (09-10 -08-06)) * 1.0 / 2
  *原始数据集为： 
  *             1100 2015-07-01
  *             1200 2015-08-08
  *             1100 2015-08-06
  *目前数据处理的程序环境为：spark shell
  *还有些问题，对于reduceByKey的结果，要排序，从小到大
  */
  
./bin/spark-shell --driver-memory 3g		 
val rawData = sc.textFile("file:///tmp/testid.txt")
val rdd00 = rawData.map(_.split("\t")).map(a => (a(0), a(1)))
val rdd11 = rdd00.reduceByKey(_ + "," + _)		                   //相同Key的值，已经放置在一起

rdd11.first._2.split(",")                                        //简单查看

//产生新的包含两个值的List
def generList2Len(strSource: String) = {
  val tranSplit = strSource.split(",")
  val tranLength = tranSplit.length
  for (i <- 0 until tranLength-1)
    yield List(tranSplit(i), tranSplit(i+1))
  }
		 
import java.text.SimpleDateFormat
import java.util.Date 
val dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")

//获取的数据格式为（Key，相邻时间差的和，相邻时间的个数， 平均的相邻时间差的和）
val summId = rdd11.map { a => 
  val geneDateList = generList2Len(a._2)
  val dateCal = geneDateList.map(date => (dateFormat.parse(date(1)).getTime() - dateFormat.parse(date(0)).getTime()) / (24 * 60 * 60 * 1000))
 (a._1, dateCal.sum, dateCal.length, BigDecimal(dateCal.sum * 1.0 / dateCal.length).setScale(2, BigDecimal.RoundingMode.HALF_UP).toDouble)
}

summId.collect.foreach(println)
  
